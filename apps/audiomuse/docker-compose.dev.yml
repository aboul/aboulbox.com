services:
  audiomuse-ai-flask:
    image: ghcr.io/neptunehub/audiomuse-ai:latest-nvidia
    container_name: audiomuse-ai-flask-app
    restart: unless-stopped
    ports:
      - 8000:8000
    environment:
      SERVICE_TYPE: "flask"
      MEDIASERVER_TYPE: "navidrome"
      NAVIDROME_URL: "${NAVIDROME_URL}"
      NAVIDROME_USER: "${NAVIDROME_USER}"
      NAVIDROME_PASSWORD: "${NAVIDROME_PASSWORD}"
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: audiomusedb
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      REDIS_URL: "${AUDIOMUSE_REDIS_URL}"
      AI_MODEL_PROVIDER: "${AI_MODEL_PROVIDER:-NONE}"
      OLLAMA_SERVER_URL: "${OLLAMA_SERVER_URL}"
      OLLAMA_MODEL_NAME: "${OLLAMA_MODEL_NAME:-mistral-small3.2:latest}"
      CLAP_ENABLED: "${CLAP_ENABLED:-true}" # Enable CLAP text search (set to false for slower systems)
      TEMP_DIR: "/app/temp_audio"
      PER_SONG_MODEL_RELOAD: "${PER_SONG_MODEL_RELOAD:-true}"
    volumes:
      - audiomuse-temp-audio-flask:/app/temp_audio
    depends_on:
      - audiomuse-redis
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    networks:
      - proxy-network
      - database-network
      - audiomuse-network

  # AudioMuse-AI RQ Worker service
  audiomuse-ai-worker:
    image: ghcr.io/neptunehub/audiomuse-ai:latest-nvidia
    container_name: audiomuse-ai-worker-instance
    restart: unless-stopped
    environment:
      SERVICE_TYPE: "worker"
      MEDIASERVER_TYPE: "navidrome"
      NAVIDROME_URL: "${NAVIDROME_URL}"
      NAVIDROME_USER: "${NAVIDROME_USER}"
      NAVIDROME_PASSWORD: "${NAVIDROME_PASSWORD}"
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB:-audiomusedb}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      REDIS_URL: "${AUDIOMUSE_REDIS_URL}"
      AI_MODEL_PROVIDER: "${AI_MODEL_PROVIDER:-NONE}"
      OLLAMA_SERVER_URL: "${OLLAMA_SERVER_URL}"
      OLLAMA_MODEL_NAME: "${OLLAMA_MODEL_NAME:-mistral-small3.2:latest}"
      CLAP_ENABLED: "${CLAP_ENABLED:-true}" # Enable CLAP text search (set to false for slower systems)
      TEMP_DIR: "/app/temp_audio"
      NVIDIA_VISIBLE_DEVICES: "${NVIDIA_VISIBLE_DEVICES}"
      NVIDIA_DRIVER_CAPABILITIES: "${NVIDIA_DRIVER_CAPABILITIES}"
      USE_GPU_CLUSTERING: "${USE_GPU_CLUSTERING:-false}"
      PER_SONG_MODEL_RELOAD: "${PER_SONG_MODEL_RELOAD:-true}"

    volumes:
      - audiomuse-temp-audio-worker:/app/temp_audio
    depends_on:
      - audiomuse-redis
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    networks:
      - database-network
      - audiomuse-network

  audiomuse-redis:
    image: redis:8-alpine
    restart: unless-stopped
    container_name: audiomuse-redis
    ports:
      - "${REDIS_PORT:-6379}:6379" # Expose Redis port to the host
    volumes:
      - audiomuse-redis-data:/data # Persistent storage for Redis data
    networks:
      - audiomuse-network

volumes:
  audiomuse-temp-audio-flask:
  audiomuse-temp-audio-worker:
  audiomuse-redis-data:

networks:
  proxy-network:
    external: true
    driver: bridge
    name: caddy_proxy-network
  database-network:
    external: true
    driver: bridge
    name: aboulbox_database-network
  audiomuse-network:
    driver: bridge
