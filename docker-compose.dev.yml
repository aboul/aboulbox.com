services:
  caddy:
    environment:
      SERVER_NAME: ${SERVER_NAME}
      CADDY_GLOBAL_OPTIONS: |
        debug
        local_certs
    volumes:
      - ${STORAGE_BASE_PATH}/caddy/Caddyfile.dev:/etc/caddy/Caddyfile:ro

  frontend:
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/dist
      - .env:/app/.env
    command: npm run dev

  backend:
    volumes:
      - .env:/app/.env
    environment:
      DEBUG: express:*
    command: node --watch app.js

  umami:
    environment:
      DEBUG: umami:*
      DISABLE_TELEMETRY: 1
      DISABLE_LOGIN: 1
      LOG_QUERY: 1

  homepage:
    volumes:
      - .env.dev:/app/.env
      - ${STORAGE_BASE_PATH}/homepage/config/services.dev.yaml:/app/config/services.yaml:ro
      - ${STORAGE_BASE_PATH}/homepage/config/widgets.dev.yaml:/app/config/widgets.yaml:ro

  docusaurus:
    environment:
      DEBUG: search-local:*
    volumes:
      - ./docusaurus/Wiki:/opt/docusaurus
      - ./docs/personal-site:/opt/docusaurus/docs/personal-site
    command: npm run start -- --host 0.0.0.0 --poll 1000

  glances:
    volumes:
      - ${STORAGE_BASE_PATH}/glances/conf/glances.dev.conf:/etc/glances/glances.conf:ro
      - /media/HOME:/ssd:ro
      - /media/HOMEBACK:/backups:ro
    environment:
      - "GLANCES_OPT=-w --debug"

  # audiomuse-ai-flask:
  #   image: ghcr.io/neptunehub/audiomuse-ai:latest-nvidia
  #   container_name: audiomuse-ai-flask-app
  #   restart: unless-stopped
  #   ports:
  #     - 8000:8000
  #   environment:
  #     SERVICE_TYPE: "flask"
  #     MEDIASERVER_TYPE: "navidrome"
  #     NAVIDROME_URL: "${NAVIDROME_URL}"
  #     NAVIDROME_USER: "${NAVIDROME_USER}"
  #     NAVIDROME_PASSWORD: "${NAVIDROME_PASSWORD}"
  #     POSTGRES_USER: ${POSTGRES_USER}
  #     POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  #     POSTGRES_DB: audiomusedb
  #     POSTGRES_HOST: ${POSTGRES_HOST}
  #     POSTGRES_PORT: ${POSTGRES_PORT}
  #     REDIS_URL: "${AUDIOMUSE_REDIS_URL}"
  #     AI_MODEL_PROVIDER: "${AI_MODEL_PROVIDER:-NONE}"
  #     OLLAMA_SERVER_URL: "${OLLAMA_SERVER_URL}"
  #     OLLAMA_MODEL_NAME: "${OLLAMA_MODEL_NAME:-mistral-small3.2:latest}"
  #     CLAP_ENABLED: "${CLAP_ENABLED:-true}" # Enable CLAP text search (set to false for slower systems)
  #     TEMP_DIR: "/app/temp_audio"
  #     PER_SONG_MODEL_RELOAD: "${PER_SONG_MODEL_RELOAD:-true}"
  #   volumes:
  #     - audiomuse-temp-audio-flask:/app/temp_audio
  #   depends_on:
  #     - audiomuse-redis
  #     - db
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: ["0"]
  #             capabilities: [gpu]
  #   networks:
  #     - portfolio-net

  # # AudioMuse-AI RQ Worker service
  # audiomuse-ai-worker:
  #   image: ghcr.io/neptunehub/audiomuse-ai:latest-nvidia
  #   container_name: audiomuse-ai-worker-instance
  #   restart: unless-stopped
  #   environment:
  #     SERVICE_TYPE: "worker"
  #     MEDIASERVER_TYPE: "navidrome"
  #     NAVIDROME_URL: "${NAVIDROME_URL}"
  #     NAVIDROME_USER: "${NAVIDROME_USER}"
  #     NAVIDROME_PASSWORD: "${NAVIDROME_PASSWORD}"
  #     POSTGRES_USER: ${POSTGRES_USER}
  #     POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  #     POSTGRES_DB: ${POSTGRES_DB:-audiomusedb}
  #     POSTGRES_HOST: ${POSTGRES_HOST}
  #     POSTGRES_PORT: ${POSTGRES_PORT}
  #     REDIS_URL: "${AUDIOMUSE_REDIS_URL}"
  #     AI_MODEL_PROVIDER: "${AI_MODEL_PROVIDER:-NONE}"
  #     OLLAMA_SERVER_URL: "${OLLAMA_SERVER_URL}"
  #     OLLAMA_MODEL_NAME: "${OLLAMA_MODEL_NAME:-mistral-small3.2:latest}"
  #     CLAP_ENABLED: "${CLAP_ENABLED:-true}" # Enable CLAP text search (set to false for slower systems)
  #     TEMP_DIR: "/app/temp_audio"
  #     NVIDIA_VISIBLE_DEVICES: "${NVIDIA_VISIBLE_DEVICES}"
  #     NVIDIA_DRIVER_CAPABILITIES: "${NVIDIA_DRIVER_CAPABILITIES}"
  #     USE_GPU_CLUSTERING: "${USE_GPU_CLUSTERING:-false}"
  #     PER_SONG_MODEL_RELOAD: "${PER_SONG_MODEL_RELOAD:-true}"
      
  #   volumes:
  #     - audiomuse-temp-audio-worker:/app/temp_audio
  #   depends_on:
  #     - audiomuse-redis
  #     - db
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: ["0"]
  #             capabilities: [gpu]
  #   networks:
  #     - portfolio-net

  # audiomuse-redis:
  #   image: redis:7-alpine
  #   restart: unless-stopped
  #   container_name: audiomuse-redis
  #   ports:
  #     - "${REDIS_PORT:-6379}:6379" # Expose Redis port to the host
  #   volumes:
  #     - audiomuse-redis-data:/data # Persistent storage for Redis data
  #   networks:
  #     - portfolio-net

volumes:
  audiomuse-temp-audio-flask:
  audiomuse-temp-audio-worker:
  audiomuse-redis-data: